{
  "id": "01-micrograd-ex007",
  "lectureId": "01-micrograd",
  "segmentId": "01-micrograd-seg07",
  "title": "Manual Backward for Addition",
  "difficulty": "easy",
  "order": 7,
  "topics": ["backpropagation", "chain-rule"],
  "description": "Given `a = Value(2.0)`, `b = Value(3.0)`, `c = a + b`, and `c.grad = 1.0`, manually set `a.grad` and `b.grad`.\n\nRecall: for addition, the gradient flows equally to both inputs. If dc/dc = 1.0, then dc/da = 1.0 and dc/db = 1.0.",
  "starterCode": "class Value:\n    def __init__(self, data, _children=(), _op=''):\n        self.data = data\n        self.grad = 0.0\n        self._children = set(_children)\n        self._op = _op\n        self._backward = lambda: None\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        return Value(self.data + other.data, (self, other), '+')\n\n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        return Value(self.data * other.data, (self, other), '*')\n\ndef manual_backward_add():\n    a = Value(2.0)\n    b = Value(3.0)\n    c = a + b\n    c.grad = 1.0\n    # Set a.grad and b.grad manually\n    pass\n    return a, b, c\n",
  "solutionCode": "class Value:\n    def __init__(self, data, _children=(), _op=''):\n        self.data = data\n        self.grad = 0.0\n        self._children = set(_children)\n        self._op = _op\n        self._backward = lambda: None\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        return Value(self.data + other.data, (self, other), '+')\n\n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        return Value(self.data * other.data, (self, other), '*')\n\ndef manual_backward_add():\n    a = Value(2.0)\n    b = Value(3.0)\n    c = a + b\n    c.grad = 1.0\n    a.grad = 1.0  # dc/da = 1.0\n    b.grad = 1.0  # dc/db = 1.0\n    return a, b, c\n",
  "testCode": "try:\n    a, b, c = manual_backward_add()\n    assert a.grad == 1.0\n    print(\"PASS: a.grad == 1.0\")\nexcept:\n    print(\"FAIL: a.grad == 1.0\")\n\ntry:\n    a, b, c = manual_backward_add()\n    assert b.grad == 1.0\n    print(\"PASS: b.grad == 1.0\")\nexcept:\n    print(\"FAIL: b.grad == 1.0\")\n\ntry:\n    a, b, c = manual_backward_add()\n    assert c.data == 5.0\n    print(\"PASS: c.data == 5.0\")\nexcept:\n    print(\"FAIL: c.data == 5.0\")\n\ntry:\n    a, b, c = manual_backward_add()\n    assert c.grad == 1.0\n    print(\"PASS: c.grad == 1.0\")\nexcept:\n    print(\"FAIL: c.grad == 1.0\")\n",
  "hints": [
    "For c = a + b, dc/da = 1 and dc/db = 1",
    "The gradient of addition distributes equally"
  ]
}
